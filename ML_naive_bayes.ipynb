{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiqingZhou694/Fake-News-Detection-/blob/main/ML_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import random"
      ],
      "metadata": {
        "id": "_RRPWGxjD48G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code combine\n",
        "\n",
        "# read the files\n",
        "fake = pd.read_csv(\"./Input/Fake.csv\")\n",
        "real = pd.read_csv(\"./Input/True.csv\")\n",
        "\n",
        "# Insert the column class for true or fake, 1 or 0\n",
        "fake[\"class\"] = 0\n",
        "real[\"class\"] = 1\n",
        "\n",
        "#combine the data\n",
        "df = pd.concat([fake, real], ignore_index=True)\n",
        "\n",
        "#clean data\n",
        "# This inculde the column title, text, and class\n",
        "df = df[[\"title\",\"text\", \"class\"]]\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "#============================The trainning for title ==========================================\n",
        "\n",
        "# Create a vectorizer, retaining up to 5000 words\n",
        "tfidf_title = TfidfVectorizer(stop_words='english', max_features=5000)# TF-IDF\n",
        "# title-only is title, Text change to text\n",
        "X_title = tfidf_title.fit_transform(df[\"title\"])\n",
        "y = df[\"class\"]\n",
        "\n",
        "# Splitting Training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_title, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Naive Bayes\n",
        "NB = MultinomialNB()\n",
        "NB_title = NB.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_pred = NB_title.predict(X_test)\n",
        "\n",
        "#============================ The trainning for text ==========================================\n",
        "\n",
        "# Create a vectorizer, retaining up to 5000 words\n",
        "tfidf_text = TfidfVectorizer(stop_words='english', max_features=5000)# TF-IDF\n",
        "# title-only is title, Text change to text\n",
        "X_text = tfidf_title.fit_transform(df[\"text\"])\n",
        "y = df[\"class\"]\n",
        "\n",
        "# Splitting Training\n",
        "X_train_tx, X_test_tx, y_train_tx, y_test_tx = train_test_split(X_text, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Naive Bayes\n",
        "NB_text = MultinomialNB().fit(X_train_tx, y_train_tx)\n",
        "\n",
        "#============================ The trainning for both title and text ==========================================\n",
        "\n",
        "# combine the title and the text\n",
        "df[\"combined\"] = df[\"title\"] + \" \" + df[\"text\"]\n",
        "tfidf_combined = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_comb = tfidf_combined.fit_transform(df[\"combined\"])\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_comb, y, test_size=0.2, stratify=y, random_state=42)\n",
        "NB_combined = MultinomialNB().fit(X_train_c, y_train_c)\n",
        "\n",
        "\n",
        "# report\n",
        "print(\"Classification Report Title Only:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Classification Report Text Only:\")\n",
        "print(classification_report(y_test_tx, NB_text.predict(X_test_tx)))\n",
        "print(\"Classification Report Combined Text and Title:\")\n",
        "print(classification_report(y_test_c, NB_combined.predict(X_test_c)))\n",
        "\n",
        "# Plot confusion matrix\n",
        "\n",
        "#============== Title ================\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix for Title\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#============== Text ================\n",
        "\n",
        "cm = confusion_matrix(y_test_tx, NB_text.predict(X_test_tx))\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix for Text\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#============== both ================\n",
        "\n",
        "cm = confusion_matrix(y_test_c, NB_combined.predict(X_test_c))\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix for Combine\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "y-A_N5bAdX_T",
        "outputId": "6b50eb12-8d19-4b17-93a5-b67245a3e7af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec7a446d0250>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# read the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Input/Fake.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Input/True.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "\n",
        "log_prob = NB.feature_log_prob_  # shape: [2, n_features]\n",
        "classes = NB.classes_            # [\"FAKE\", \"REAL\"]\n",
        "\n",
        "\n",
        "def show_top_keywords(log_prob, feature_names, class_index, class_label, top_n=20):\n",
        "    top_indices = np.argsort(log_prob[class_index])[::-1][:top_n]\n",
        "    print(f\"\\nTop {top_n} keywords for class: {class_label}\")\n",
        "    for i in top_indices:\n",
        "        print(f\"{feature_names[i]:<20} {log_prob[class_index][i]:.4f}\")\n",
        "\n",
        "\n",
        "show_top_keywords(log_prob, feature_names, class_index=0, class_label=classes[0])\n",
        "\n",
        "\n",
        "show_top_keywords(log_prob, feature_names, class_index=1, class_label=classes[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhHK6a_5VQbB",
        "outputId": "5d82ee2a-c1a0-401c-e242-945cd1f36be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 keywords for class: 0\n",
            "video                -4.1062\n",
            "trump                -4.1476\n",
            "hillary              -5.1027\n",
            "obama                -5.1141\n",
            "watch                -5.1232\n",
            "just                 -5.2484\n",
            "donald               -5.5572\n",
            "gop                  -5.6294\n",
            "clinton              -5.6614\n",
            "president            -5.6927\n",
            "tweets               -5.8406\n",
            "black                -5.8474\n",
            "breaking             -5.8745\n",
            "news                 -5.8799\n",
            "white                -5.9649\n",
            "new                  -5.9656\n",
            "gets                 -6.0108\n",
            "america              -6.0371\n",
            "republicans          -6.1447\n",
            "muslim               -6.1770\n",
            "\n",
            "Top 20 keywords for class: 1\n",
            "trump                -4.4147\n",
            "says                 -4.5617\n",
            "house                -5.0947\n",
            "russia               -5.4129\n",
            "korea                -5.4923\n",
            "north                -5.5039\n",
            "senate               -5.5802\n",
            "new                  -5.5867\n",
            "china                -5.6061\n",
            "white                -5.6203\n",
            "court                -5.6590\n",
            "tax                  -5.7046\n",
            "republican           -5.7370\n",
            "state                -5.7900\n",
            "clinton              -5.7988\n",
            "eu                   -5.8096\n",
            "election             -5.8700\n",
            "deal                 -5.8840\n",
            "obama                -5.9040\n",
            "talks                -5.9129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Testing\n",
        "def output_label(n):\n",
        "    if n == 0:\n",
        "        return \"Fake News\"\n",
        "    elif n == 1:\n",
        "        return \"Real News\"\n",
        "def testing(news):\n",
        "    # create DataFrame\n",
        "    new_data = pd.DataFrame({\"title\": [news]})\n",
        "    # text to vectors\n",
        "    new_x = tfidf.transform(new_data[\"title\"])\n",
        "\n",
        "    # Model predictions Naive Bayes, Logistic\n",
        "    pred_NB = NB.predict(new_x)[0]\n",
        "\n",
        "    # Output\n",
        "    print(\"Model Predictions for the input:\\n\")\n",
        "    print(\"Text: \", news)\n",
        "    print(\"\\nNaive Bayes:\", output_label(pred_NB))\n",
        "\n",
        "testing(\"Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\")\n",
        "\n",
        "# Combine title and text for the input\n",
        "random_index = random.choice(df.index)\n",
        "combined_text = df.loc[random_index, 'title']\n",
        "\n",
        "testing(combined_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMv1vjREF-xe",
        "outputId": "c7507b92-08d1-4e9a-b92a-79daa0da07c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Predictions for the input:\n",
            "\n",
            "Text:  Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\n",
            "\n",
            "Naive Bayes: Fake News\n",
            "Model Predictions for the input:\n",
            "\n",
            "Text:  BOOM! 4 VENUES CANCEL KATHY GRIFFIN Appearances After She Blames Trump For Her Career Ending Decision To Pose With His Severed Head\n",
            "\n",
            "Naive Bayes: Fake News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Testing\n",
        "def output_label(n):\n",
        "    if n == 0:\n",
        "        return \"Fake News\"\n",
        "    elif n == 1:\n",
        "        return \"Real News\"\n",
        "def testing(news_title, news_text, mode=\"title\"):\n",
        "    if mode == \"title\":\n",
        "        input_text = news_title\n",
        "    elif mode == \"text\":\n",
        "        input_text = news_text\n",
        "    elif mode == \"both\":\n",
        "        input_text = news_title + \" \" + news_text\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'title', 'text', or 'both'.\")\n",
        "\n",
        "    new_data = pd.DataFrame({\"input\": [input_text]})\n",
        "    new_x = tfidf.transform(new_data[\"input\"])\n",
        "    pred_NB = NB.predict(new_x)[0]\n",
        "\n",
        "    print(f\"\\n--- Testing mode: {mode.upper()} ---\")\n",
        "    print(\"Title:\", news_title)\n",
        "    print(\"Text:\", news_text[:100], \"...\" if len(news_text) > 100 else \"\")\n",
        "    print(\"Prediction:\", output_label(pred_NB))\n",
        "\n",
        "# random the Combine Fake and True data for testing\n",
        "random_index = random.choice(df.index)\n",
        "title = df.loc[random_index, \"title\"]\n",
        "text = df.loc[random_index, \"text\"]\n",
        "\n",
        "# test title/ text/ both\n",
        "testing(title, text, mode=\"title\")\n",
        "testing(title, text, mode=\"text\")\n",
        "testing(title, text, mode=\"both\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox3dt-m8aSLu",
        "outputId": "caeb4dc9-9039-4ba6-e84e-d5fe064f8579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing mode: TITLE ---\n",
            "Title: MASSACHUSETTS VOTES TO IGNORE FED LAW and Let Illegals Go…This Sanctuary State Endangers All Americans!\n",
            "Text: MASSACHUSETTS IS NOW A SANCTUARY STATE! The Massachusetts Supreme Court just ruled that illegals are ...\n",
            "Prediction: Fake News\n",
            "\n",
            "--- Testing mode: TEXT ---\n",
            "Title: MASSACHUSETTS VOTES TO IGNORE FED LAW and Let Illegals Go…This Sanctuary State Endangers All Americans!\n",
            "Text: MASSACHUSETTS IS NOW A SANCTUARY STATE! The Massachusetts Supreme Court just ruled that illegals are ...\n",
            "Prediction: Real News\n",
            "\n",
            "--- Testing mode: BOTH ---\n",
            "Title: MASSACHUSETTS VOTES TO IGNORE FED LAW and Let Illegals Go…This Sanctuary State Endangers All Americans!\n",
            "Text: MASSACHUSETTS IS NOW A SANCTUARY STATE! The Massachusetts Supreme Court just ruled that illegals are ...\n",
            "Prediction: Real News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_testing(n=100):\n",
        "    agree_title = 0\n",
        "    agree_text = 0\n",
        "\n",
        "    for _ in range(n):\n",
        "        random_index = random.choice(df.index)\n",
        "        title = df.loc[random_index, \"title\"]\n",
        "        text = df.loc[random_index, \"text\"]\n",
        "        combined = title + \" \" + text\n",
        "\n",
        "        # 向量化\n",
        "        x_title = tfidf.transform([title])\n",
        "        x_text = tfidf.transform([text])\n",
        "        x_both = tfidf.transform([combined])\n",
        "\n",
        "        # 预测\n",
        "        pred_title = NB.predict(x_title)[0]\n",
        "        pred_text = NB.predict(x_text)[0]\n",
        "        pred_both = NB.predict(x_both)[0]\n",
        "\n",
        "        # 比较是否一致\n",
        "        if pred_title == pred_both:\n",
        "            agree_title += 1\n",
        "        if pred_text == pred_both:\n",
        "            agree_text += 1\n",
        "\n",
        "    print(f\"\\nCompared against BOTH (title+text) on {n} samples:\")\n",
        "    print(f\"TITLE agreement: {agree_title/n:.1%}\")\n",
        "    print(f\"TEXT  agreement: {agree_text/n:.1%}\")\n",
        "\n",
        "evaluate_testing(n=100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmdykMIzn3Jq",
        "outputId": "3a5d969d-6c8e-4a47-de5a-e1fc473f3dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Compared against BOTH (title+text) on 100 samples:\n",
            "TITLE agreement: 93.0%\n",
            "TEXT  agreement: 99.0%\n"
          ]
        }
      ]
    }
  ]
}